{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Notebook starts from Preprocessed Dataframework. \"df_spark.csv\" is the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = pd.read_csv('df_spark.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    0     1     2    3    4     5    6    7      8    9   10   11\n",
       "0           0  7.0  21.0  30.0  2.0  3.0  30.0  2.0  3.0   59.0  7.0  2.0  0.0\n",
       "1           1  7.0  32.0  70.0  2.0  4.0  68.0  2.0  4.0  134.0  7.0  2.0  0.0\n",
       "2           2  7.0  15.0   1.0  2.0  2.0   0.0  2.0  2.0    0.0  7.0  2.0  0.0\n",
       "3           3  7.0  33.0  77.0  2.0  7.0  73.0  2.0  7.0  144.0  7.0  2.0  0.0\n",
       "4           4  7.0  55.0  78.0  3.0  7.0  74.0  3.0  7.0  146.0  8.0  2.0  0.0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = df_spark.drop(columns=\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2    3    4     5    6    7      8    9   10   11\n",
       "0  7.0  21.0  30.0  2.0  3.0  30.0  2.0  3.0   59.0  7.0  2.0  0.0\n",
       "1  7.0  32.0  70.0  2.0  4.0  68.0  2.0  4.0  134.0  7.0  2.0  0.0\n",
       "2  7.0  15.0   1.0  2.0  2.0   0.0  2.0  2.0    0.0  7.0  2.0  0.0\n",
       "3  7.0  33.0  77.0  2.0  7.0  73.0  2.0  7.0  144.0  7.0  2.0  0.0\n",
       "4  7.0  55.0  78.0  3.0  7.0  74.0  3.0  7.0  146.0  8.0  2.0  0.0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In the following code X contains features and y contains label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_spark.iloc[:,0].values\n",
    "X = df_spark.iloc[:,1:].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The whole dataset is split into 80:20 ratio. X_train contains 80% of the features, X_test contains 20% of the features and y_train contains 80% corresponding label of X_train and y_test contains 20% corresponding label of X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.20, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5-Fold Cross validation Estimation for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr = Pipeline([('scl', StandardScaler()),('clf', LogisticRegression(penalty='l2', random_state=0))])\n",
    "train_sizes, train_scores, test_scores = learning_curve(estimator=pipe_lr,X=X, y=y, train_sizes=np.linspace(0.2,1.0,5), cv=5, n_jobs=-1)\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57270\n",
      "114540\n",
      "171811\n",
      "229081\n",
      "286352\n"
     ]
    }
   ],
   "source": [
    "for i in train_sizes:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9864187183516675\n",
      "0.986911122751877\n",
      "0.9868308781160694\n",
      "0.9865846578284538\n",
      "0.9883136838576296\n"
     ]
    }
   ],
   "source": [
    "for i in train_mean:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8951165571047358\n",
      "0.8779824156058529\n",
      "0.9781109282961822\n",
      "0.9846064215159688\n",
      "0.9880902458937426\n"
     ]
    }
   ],
   "source": [
    "for i in test_mean:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5-Fold Cross validation Estimation for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_svc = Pipeline([('scl', StandardScaler()),('clf', LinearSVC())])\n",
    "train_sizes_svc, train_scores_svc, test_scores_svc = learning_curve(estimator=pipe_svc,X=X, y=y, train_sizes=np.linspace(0.2,1.0,5), cv=5, n_jobs=-1)\n",
    "train_mean_svc = np.mean(train_scores_svc, axis=1)\n",
    "train_std_svc = np.std(train_scores_svc, axis=1)\n",
    "test_mean_svc = np.mean(test_scores_svc, axis=1)\n",
    "test_std_svc = np.std(test_scores_svc, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9826540946394273\n",
      "0.981639601885804\n",
      "0.9856668082951614\n",
      "0.9823267752454372\n",
      "0.9829803877744873\n"
     ]
    }
   ],
   "source": [
    "for i in train_mean_svc:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9603062688826753\n",
      "0.9711907748218677\n",
      "0.9774767477765417\n",
      "0.9796111876180309\n",
      "0.9825781652457415\n"
     ]
    }
   ],
   "source": [
    "for i in test_mean_svc:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5-Fold Cross validation Estimation for Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_tree = Pipeline([('scl', StandardScaler()),('clf', tree.DecisionTreeClassifier())])\n",
    "train_sizes_tree, train_scores_tree, test_scores_tree = learning_curve(estimator=pipe_tree,X=X, y=y, train_sizes=np.linspace(0.2,1.0,5), cv=5, n_jobs=-1)\n",
    "train_mean_tree = np.mean(train_scores_tree, axis=1)\n",
    "train_std_tree = np.std(train_scores_tree, axis=1)\n",
    "test_mean_tree = np.mean(test_scores_tree, axis=1)\n",
    "test_std_tree = np.std(test_scores_tree, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9866876200453991\n",
      "0.9884634188929631\n",
      "0.9906874414327372\n",
      "0.9928566751498378\n",
      "0.9942169078616528\n"
     ]
    }
   ],
   "source": [
    "for i in train_mean_tree:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9693692248374592\n",
      "0.8910209056389953\n",
      "0.9801699251057695\n",
      "0.9884115207121322\n",
      "0.9934933756651478\n"
     ]
    }
   ],
   "source": [
    "for i in test_mean_tree:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5-Fold Cross validation Estimation for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_rnd = Pipeline([('scl', StandardScaler()),('clf', RandomForestClassifier(n_estimators=10))])\n",
    "train_sizes_rnd, train_scores_rnd, test_scores_rnd = learning_curve(estimator=pipe_rnd,X=X, y=y, train_sizes=np.linspace(0.2,1.0,5), cv=5, n_jobs=-1)\n",
    "train_mean_rnd = np.mean(train_scores_rnd, axis=1)\n",
    "train_std_rnd = np.std(train_scores_rnd, axis=1)\n",
    "test_mean_rnd = np.mean(test_scores_rnd, axis=1)\n",
    "test_std_rnd = np.std(test_scores_rnd, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9866876200453991\n",
      "0.9884634188929631\n",
      "0.9906874414327372\n",
      "0.9928566751498378\n",
      "0.9942162094205733\n"
     ]
    }
   ],
   "source": [
    "for i in train_mean_rnd:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9266022805397951\n",
      "0.9296446973359276\n",
      "0.9801894813779459\n",
      "0.9885540029655276\n",
      "0.9932195868400298\n"
     ]
    }
   ],
   "source": [
    "for i in test_mean_rnd:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5-Fold Cross validation Estimation for ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(50,), max_iter=10, alpha=1e-4, solver='sgd', verbose=10, tol=1e-4, random_state=1, learning_rate_init=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_mlp = Pipeline([('scl', StandardScaler()),('clf', mlp)])\n",
    "train_sizes_mlp, train_scores_mlp, test_scores_mlp = learning_curve(estimator=pipe_mlp,X=X, y=y, train_sizes=np.linspace(0.2,1.0,5), cv=5, n_jobs=-1)\n",
    "train_mean_mlp = np.mean(train_scores_mlp, axis=1)\n",
    "train_std_mlp = np.std(train_scores_mlp, axis=1)\n",
    "test_mean_mlp = np.mean(test_scores_mlp, axis=1)\n",
    "test_std_mlp = np.std(test_scores_mlp, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.985339619346953\n",
      "0.9879710144927536\n",
      "0.9900728125672977\n",
      "0.9914135174894468\n",
      "0.9941638263396101\n"
     ]
    }
   ],
   "source": [
    "for i in train_mean_mlp:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9150305087344645\n",
      "0.9029139603799254\n",
      "0.9762279246286383\n",
      "0.9843633560982139\n",
      "0.9930882811268583\n"
     ]
    }
   ],
   "source": [
    "for i in test_mean_mlp:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean values of Training and Testing accuracies and Standard Deviation of Training and Testing accuracies are given below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9870118121811394,\n",
       " 0.9830535335680635,\n",
       " 0.990582412676518,\n",
       " 0.990582272988302,\n",
       " 0.9897921580472122)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(train_mean) , np.mean(train_mean_svc), np.mean(train_mean_tree), np.mean(train_mean_rnd), np.mean(train_mean_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0019075867098246994,\n",
       " 0.0028917520586866515,\n",
       " 0.0018731735038651147,\n",
       " 0.001873285301161849,\n",
       " 0.002748992366444652)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(train_std) , np.mean(train_std_svc), np.mean(train_std_tree), np.mean(train_std_rnd), np.mean(train_std_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9447813136832964,\n",
       " 0.9742326288689714,\n",
       " 0.9644929903919008,\n",
       " 0.9636420098118453,\n",
       " 0.95432480619362)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(test_mean) , np.mean(test_mean_svc), np.mean(test_mean_tree), np.mean(test_mean_rnd), np.mean(test_mean_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.03346224583422917,\n",
       " 0.00847991244105734,\n",
       " 0.026226805480562488,\n",
       " 0.02798116250265864,\n",
       " 0.026923883589396635)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(test_std) , np.mean(test_std_svc), np.mean(test_std_tree), np.mean(test_std_rnd), np.mean(test_std_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics Calculations for Logisitic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nikhil Venkat\\anaconda3\\envs\\Tf2\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "pipe_lr = pipe_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = pipe_lr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = pipe_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9885455662960273"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9881406361312493"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['Normal', 'DoSattack', 'scan', 'malitiousControl', 'malitiousOperation', 'spying', 'dataProbing', 'wrongSetUp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nikhil Venkat\\anaconda3\\envs\\Tf2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Nikhil Venkat\\anaconda3\\envs\\Tf2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "            Normal       0.96      0.65      0.78      4602\n",
      "         DoSattack       1.00      0.59      0.74       279\n",
      "              scan       0.98      0.96      0.97       720\n",
      "  malitiousControl       0.97      0.48      0.64       650\n",
      "malitiousOperation       0.90      0.47      0.62      1242\n",
      "            spying       0.00      0.00      0.00       412\n",
      "       dataProbing       0.90      1.00      0.95        94\n",
      "        wrongSetUp       0.99      1.00      0.99    278353\n",
      "\n",
      "          accuracy                           0.99    286352\n",
      "         macro avg       0.84      0.64      0.71    286352\n",
      "      weighted avg       0.99      0.99      0.99    286352\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nikhil Venkat\\anaconda3\\envs\\Tf2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred_train, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nikhil Venkat\\anaconda3\\envs\\Tf2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Nikhil Venkat\\anaconda3\\envs\\Tf2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "            Normal       0.95      0.66      0.78      1178\n",
      "         DoSattack       1.00      0.57      0.73        63\n",
      "              scan       0.98      0.97      0.98       169\n",
      "  malitiousControl       0.99      0.50      0.67       155\n",
      "malitiousOperation       0.88      0.41      0.56       305\n",
      "            spying       0.00      0.00      0.00       120\n",
      "       dataProbing       0.93      1.00      0.97        28\n",
      "        wrongSetUp       0.99      1.00      0.99     69571\n",
      "\n",
      "          accuracy                           0.99     71589\n",
      "         macro avg       0.84      0.64      0.71     71589\n",
      "      weighted avg       0.99      0.99      0.99     71589\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nikhil Venkat\\anaconda3\\envs\\Tf2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_test, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "775--0--0--0--0--0--0--403--\n",
      "0--36--0--0--0--0--0--27--\n",
      "0--0--164--0--0--0--0--5--\n",
      "0--0--0--78--0--0--0--77--\n",
      "5--0--2--0--126--0--2--170--\n",
      "0--0--0--0--16--0--0--104--\n",
      "0--0--0--0--0--0--28--0--\n",
      "34--0--1--1--2--0--0--69533--\n"
     ]
    }
   ],
   "source": [
    "for i in cnf_matrix:\n",
    "    for j in i:\n",
    "        print(j, end='--')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics Calculations for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nikhil Venkat\\anaconda3\\envs\\Tf2\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "pipe_svc = pipe_svc.fit(X_train, y_train)\n",
    "y_pred_train = pipe_svc.predict(X_train)\n",
    "y_pred_test = pipe_svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9826332625579706, 0.9827627149422398)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train, y_pred_train), accuracy_score(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nikhil Venkat\\anaconda3\\envs\\Tf2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "            Normal       0.97      0.65      0.78      4602\n",
      "         DoSattack       0.00      0.00      0.00       279\n",
      "              scan       0.78      0.04      0.07       720\n",
      "  malitiousControl       1.00      0.16      0.27       650\n",
      "malitiousOperation       0.00      0.00      0.00      1242\n",
      "            spying       0.00      0.00      0.00       412\n",
      "       dataProbing       0.00      0.00      0.00        94\n",
      "        wrongSetUp       0.98      1.00      0.99    278353\n",
      "\n",
      "          accuracy                           0.98    286352\n",
      "         macro avg       0.47      0.23      0.26    286352\n",
      "      weighted avg       0.98      0.98      0.98    286352\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nikhil Venkat\\anaconda3\\envs\\Tf2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Nikhil Venkat\\anaconda3\\envs\\Tf2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred_train, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "            Normal       0.96      0.66      0.78      1178\n",
      "         DoSattack       0.00      0.00      0.00        63\n",
      "              scan       0.83      0.06      0.11       169\n",
      "  malitiousControl       1.00      0.21      0.35       155\n",
      "malitiousOperation       0.00      0.00      0.00       305\n",
      "            spying       0.00      0.00      0.00       120\n",
      "       dataProbing       0.00      0.00      0.00        28\n",
      "        wrongSetUp       0.98      1.00      0.99     69571\n",
      "\n",
      "          accuracy                           0.98     71589\n",
      "         macro avg       0.47      0.24      0.28     71589\n",
      "      weighted avg       0.98      0.98      0.98     71589\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nikhil Venkat\\anaconda3\\envs\\Tf2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Nikhil Venkat\\anaconda3\\envs\\Tf2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Nikhil Venkat\\anaconda3\\envs\\Tf2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_test, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "775--0--0--0--0--0--0--403--\n",
      "0--0--0--0--0--0--0--63--\n",
      "0--0--10--0--0--0--0--159--\n",
      "0--0--0--33--0--0--0--122--\n",
      "0--0--2--0--0--0--0--303--\n",
      "0--0--0--0--0--0--0--120--\n",
      "0--0--0--0--0--0--0--28--\n",
      "34--0--0--0--0--0--0--69537--\n"
     ]
    }
   ],
   "source": [
    "cnf_matrix = confusion_matrix(y_test, y_pred_test)\n",
    "for i in cnf_matrix:\n",
    "    for j in i:\n",
    "        print(j, end='--')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics Calculations for Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_tree = pipe_tree.fit(X_train, y_train)\n",
    "y_pred_train = pipe_tree.predict(X_train)\n",
    "y_pred_test = pipe_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9942413532994356, 0.994091271005322)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train, y_pred_train), accuracy_score(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "            Normal       0.98      0.65      0.78      4602\n",
      "         DoSattack       1.00      1.00      1.00       279\n",
      "              scan       1.00      1.00      1.00       720\n",
      "  malitiousControl       1.00      1.00      1.00       650\n",
      "malitiousOperation       1.00      1.00      1.00      1242\n",
      "            spying       1.00      1.00      1.00       412\n",
      "       dataProbing       1.00      1.00      1.00        94\n",
      "        wrongSetUp       0.99      1.00      1.00    278353\n",
      "\n",
      "          accuracy                           0.99    286352\n",
      "         macro avg       1.00      0.96      0.97    286352\n",
      "      weighted avg       0.99      0.99      0.99    286352\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred_train, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "            Normal       0.98      0.66      0.79      1178\n",
      "         DoSattack       1.00      1.00      1.00        63\n",
      "              scan       1.00      1.00      1.00       169\n",
      "  malitiousControl       1.00      1.00      1.00       155\n",
      "malitiousOperation       0.99      1.00      1.00       305\n",
      "            spying       1.00      1.00      1.00       120\n",
      "       dataProbing       1.00      1.00      1.00        28\n",
      "        wrongSetUp       0.99      1.00      1.00     69571\n",
      "\n",
      "          accuracy                           0.99     71589\n",
      "         macro avg       1.00      0.96      0.97     71589\n",
      "      weighted avg       0.99      0.99      0.99     71589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_test, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "775--0--0--0--0--0--0--403--\n",
      "0--63--0--0--0--0--0--0--\n",
      "0--0--169--0--0--0--0--0--\n",
      "0--0--0--155--0--0--0--0--\n",
      "0--0--0--0--305--0--0--0--\n",
      "0--0--0--0--0--120--0--0--\n",
      "0--0--0--0--0--0--28--0--\n",
      "18--0--0--0--2--0--0--69551--\n"
     ]
    }
   ],
   "source": [
    "cnf_matrix = confusion_matrix(y_test, y_pred_test)\n",
    "for i in cnf_matrix:\n",
    "    for j in i:\n",
    "        print(j, end='--')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics Calculations for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_rnd = pipe_rnd.fit(X_train, y_train)\n",
    "y_pred_train = pipe_rnd.predict(X_train)\n",
    "y_pred_test = pipe_rnd.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = pipe_rnd.predict(X_train)\n",
    "y_pred_test = pipe_rnd.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9942413532994356, 0.994119208258252)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train, y_pred_train), accuracy_score(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "            Normal       0.98      0.65      0.78      4602\n",
      "         DoSattack       1.00      1.00      1.00       279\n",
      "              scan       1.00      1.00      1.00       720\n",
      "  malitiousControl       1.00      1.00      1.00       650\n",
      "malitiousOperation       1.00      1.00      1.00      1242\n",
      "            spying       1.00      1.00      1.00       412\n",
      "       dataProbing       1.00      1.00      1.00        94\n",
      "        wrongSetUp       0.99      1.00      1.00    278353\n",
      "\n",
      "          accuracy                           0.99    286352\n",
      "         macro avg       1.00      0.96      0.97    286352\n",
      "      weighted avg       0.99      0.99      0.99    286352\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred_train, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "            Normal       0.98      0.66      0.79      1178\n",
      "         DoSattack       1.00      1.00      1.00        63\n",
      "              scan       1.00      1.00      1.00       169\n",
      "  malitiousControl       1.00      1.00      1.00       155\n",
      "malitiousOperation       1.00      1.00      1.00       305\n",
      "            spying       1.00      1.00      1.00       120\n",
      "       dataProbing       1.00      1.00      1.00        28\n",
      "        wrongSetUp       0.99      1.00      1.00     69571\n",
      "\n",
      "          accuracy                           0.99     71589\n",
      "         macro avg       1.00      0.96      0.97     71589\n",
      "      weighted avg       0.99      0.99      0.99     71589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_test, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "775--0--0--0--0--0--0--403--\n",
      "0--63--0--0--0--0--0--0--\n",
      "0--0--169--0--0--0--0--0--\n",
      "0--0--0--155--0--0--0--0--\n",
      "0--0--0--0--305--0--0--0--\n",
      "0--0--0--0--0--120--0--0--\n",
      "0--0--0--0--0--0--28--0--\n",
      "18--0--0--0--0--0--0--69553--\n"
     ]
    }
   ],
   "source": [
    "cnf_matrix = confusion_matrix(y_test, y_pred_test)\n",
    "for i in cnf_matrix:\n",
    "    for j in i:\n",
    "        print(j, end='--')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics Calculations for ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.05584959\n",
      "Iteration 2, loss = 0.02541104\n",
      "Iteration 3, loss = 0.01882284\n",
      "Iteration 4, loss = 0.01670067\n",
      "Iteration 5, loss = 0.01501241\n",
      "Iteration 6, loss = 0.01462482\n",
      "Iteration 7, loss = 0.01410045\n",
      "Iteration 8, loss = 0.01378341\n",
      "Iteration 9, loss = 0.01346050\n",
      "Iteration 10, loss = 0.01328968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nikhil Venkat\\anaconda3\\envs\\Tf2\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pipe_mlp = pipe_mlp.fit(X_train, y_train)\n",
    "y_pred_train = pipe_mlp.predict(X_train)\n",
    "y_pred_test = pipe_mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9942273844778454, 0.994077302378857)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train, y_pred_train), accuracy_score(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "            Normal       0.98      0.65      0.78      4602\n",
      "         DoSattack       1.00      1.00      1.00       279\n",
      "              scan       1.00      1.00      1.00       720\n",
      "  malitiousControl       1.00      1.00      1.00       650\n",
      "malitiousOperation       1.00      1.00      1.00      1242\n",
      "            spying       1.00      1.00      1.00       412\n",
      "       dataProbing       1.00      1.00      1.00        94\n",
      "        wrongSetUp       0.99      1.00      1.00    278353\n",
      "\n",
      "          accuracy                           0.99    286352\n",
      "         macro avg       1.00      0.96      0.97    286352\n",
      "      weighted avg       0.99      0.99      0.99    286352\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred_train, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(pipe_mlp,open('MLP.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "            Normal       0.98      0.66      0.79      1178\n",
      "         DoSattack       1.00      1.00      1.00        63\n",
      "              scan       0.99      1.00      1.00       169\n",
      "  malitiousControl       1.00      1.00      1.00       155\n",
      "malitiousOperation       1.00      1.00      1.00       305\n",
      "            spying       0.98      1.00      0.99       120\n",
      "       dataProbing       1.00      1.00      1.00        28\n",
      "        wrongSetUp       0.99      1.00      1.00     69571\n",
      "\n",
      "          accuracy                           0.99     71589\n",
      "         macro avg       0.99      0.96      0.97     71589\n",
      "      weighted avg       0.99      0.99      0.99     71589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_test, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  775,     0,     0,     0,     0,     0,     0,   403],\n",
       "       [    0,    63,     0,     0,     0,     0,     0,     0],\n",
       "       [    0,     0,   169,     0,     0,     0,     0,     0],\n",
       "       [    0,     0,     0,   155,     0,     0,     0,     0],\n",
       "       [    0,     0,     0,     0,   305,     0,     0,     0],\n",
       "       [    0,     0,     0,     0,     0,   120,     0,     0],\n",
       "       [    0,     0,     0,     0,     0,     0,    28,     0],\n",
       "       [   18,     0,     1,     0,     0,     2,     0, 69550]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "775--0--0--0--0--0--0--403--\n",
      "0--63--0--0--0--0--0--0--\n",
      "0--0--169--0--0--0--0--0--\n",
      "0--0--0--155--0--0--0--0--\n",
      "0--0--0--0--305--0--0--0--\n",
      "0--0--0--0--0--120--0--0--\n",
      "0--0--0--0--0--0--28--0--\n",
      "18--0--1--0--0--2--0--69550--\n"
     ]
    }
   ],
   "source": [
    "for i in cnf_matrix:\n",
    "    for j in i:\n",
    "        print(j, end='--')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
